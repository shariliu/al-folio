<!DOCTYPE html>
<html lang="en">

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Shari  Liu


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ§ </text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://www.shariliu.com/">



  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <!-- <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li> -->
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/lab/">
                lab
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/resources/">
                resources
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Shari</span>  Liu
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <picture>
    
    <source media="(max-width: 480px)" srcset="/assets/resized/headshot_2021-480x645.jpeg">
    
    <source media="(max-width: 800px)" srcset="/assets/resized/headshot_2021-800x1076.jpeg">
    
    <source media="(max-width: 1400px)" srcset="/assets/resized/headshot_2021-1400x1882.jpeg">
    
    <img class="img-fluid z-depth-1 rounded" src="/assets/img/headshot_2021.jpeg" alt="headshot_2021.jpeg">
</source></source></source></picture>

      
      
        <div class="address">
          <p>Postdoctoral Fellow</p> <p>Dept Brain and Cognitive Sciences, MIT</p>

        </div>
      
    </div>
    

    <div class="clearfix">
      <p><a href="https://docs.google.com/document/d/1RIXP5fQVd7V72sqKmlTxy8J1qRnxNOCPG2Jd4a6tpAM/edit?usp=sharing" target="_blank" rel="noopener noreferrer">curriculum vitae</a> // <a href="https://www.dropbox.com/s/viixc57ygzb9wso/shariliu_bio.txt?dl=0" target="_blank" rel="noopener noreferrer">short bio</a> // <a href="https://docs.google.com/forms/d/e/1FAIpQLScrWhVcgT3LdlUC4pErOcJZ-3Me9mzZvEX8ZQrWApfQkmS9Ew/viewform" target="_blank" rel="noopener noreferrer">request a rec letter</a></p>

<p>Every day, we look out into the world and see scenes of people in motion, and make sense of these scenes by appealing to their underlying causes. We appreciate the mental lives of others, including their desires, percepts, and beliefs, and we also see these actors as solid bodies, who can exert forces and navigate themselves through a physical world. How do our minds get so much meaning from this input, and how we grow to this knowledge over development?</p>

<p>I am currently a postdoctoral fellow in the <a href="http://saxelab.mit.edu/" target="_blank" rel="noopener noreferrer">Saxelab</a> at MIT. Prior to this, I was a graduate student at the <a href="https://www.harvardlds.org/" target="_blank" rel="noopener noreferrer">Lab For Developmental Studies</a> at Harvard.</p>

<p><strong>Starting in July 2023, I will be an Assistant Professor in the <a href="https://pbs.jhu.edu/" target="_blank" rel="noopener noreferrer">Psychological and Brain Sciences Department</a> at Johns Hopkins. I will not be recruiting this cycle (2021-2022).</strong> My lab will investigate the origins of intelligence in the minds and brains of infants, children, and adults.</p>

<p>I am committed to making science more open (transparent, reproducible, and inclusive). Part of this commitment is providing high-quality mentorship to students from all backgrounds. As a first-generation immigrant to the US who stumbled into science, I am aware that without supportive mentors, and a great deal of personal development, I would have stumbled out. Here is a <a href="https://docs.google.com/document/d/1u2olXR7QN44QGCFWaLHL33Xpr6mFnlpkxDhAryR9oGQ/edit?usp=sharing" target="_blank" rel="noopener noreferrer">working draft of my mentorship philosophy</a>.</p>


    </div>
    <hr>
    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Sep 11, 2021</th>
          <td>
            
              New working paper on automatic gaze coding. <a href="https://psyarxiv.com/yxcnb" target="_blank" rel="noopener noreferrer">Check it out!</a>

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 1, 2021</th>
          <td>
            
              Itâ€™s official - Shari will be starting a lab in July 2023 at Johns Hopkins!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 20, 2020</th>
          <td>
            
              New blog posts about testing babies online, <a href="https://medium.com/@shariliued/testing-babies-online-over-zoom-part-1-745e5246b0af" target="_blank" rel="noopener noreferrer">Part 1</a> and <a href="https://medium.com/@shariliued/testing-babies-online-over-zoom-part-2-57ea880a6961" target="_blank" rel="noopener noreferrer">Part 2</a>.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    
    <hr>
    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">PNAS</abbr>
    
  
  </div>

  <div id="LBS-2019" class="col-sm-8">
    
      <div class="title">Origins of the concepts cause, cost, and goal in prereaching infants</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Liu, S.</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=S7MpjsAAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Brooks, N. B.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://www.harvardlds.org/our-labs/spelke-labspelke-lab-members/elizabeth-spelke/" target="_blank" rel="noopener noreferrer">Spelke, E. S.</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proc. Natl. Acad. Sci. U. S. A.</em>
      
      
        Sep
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    <a href="https://osf.io/rcsns/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">materials</a>
  
    
      
      <a href="/assets/pdf/lbs_2019_pnas.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
      
      <a href="/assets/pdf/lbs_2019_pnas_sm.pdf" class="btn btn-sm z-depth-0" role="button">Supp</a>
      
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We investigated the origins and interrelations of causal knowledge and 
              knowledge of agency in 3-month-old infants, who cannot yet effect changes in 
              the world by reaching for, grasping, and picking up objects. Across 5 experiments, 
              n = 152 prereaching infants viewed object-directed reaches that varied in efficiency 
              (following the shortest physically possible path vs. a longer path), goal 
              (lifting an object vs. causing a change in its state), and causal structure 
              (action on contact vs. action at a distance and after a delay). Prereaching infants 
              showed no strong looking preference between a personâ€™s efficient and inefficient 
              reaches when the person grasped and displaced an object. When the person reached for 
              and caused a change in the state of the object on contact, however, infants looked 
              longer when this action was inefficient than when it was efficient. Three-month-old 
              infants also showed a key signature of adultsâ€™ and older infantsâ€™ causal inferences: 
              This looking preference was abolished if a short spatial and temporal gap separated 
              the action from its effect. The basic intuition that people are causal agents, who 
              navigate around physical constraints to change the state of the world, may be one 
              important foundation for infantsâ€™ ability to plan their own actions and learn from 
              the acts of others.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LBS-2019</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Origins of the concepts cause, cost, and goal in prereaching infants}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, S. and Brooks, N. B. and Spelke, E. S.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. Natl. Acad. Sci. U. S. A.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{116}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{17747--17752}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1073/pnas.1904410116}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.pnas.org/content/116/36/17747}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{lbs_2019_pnas.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{PNAS}</span><span class="p">,</span>
  <span class="na">materials</span> <span class="p">=</span> <span class="s">{https://osf.io/rcsns/}</span><span class="p">,</span>
  <span class="na">supp</span> <span class="p">=</span> <span class="s">{lbs_2019_pnas_sm.pdf}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Frontiers Psych</abbr>
    
  
  </div>

  <div id="Chuey2021-oj" class="col-sm-8">
    
      <div class="title">Moderated online data-collection for developmental research:
              Methods and replications</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=HtOhmBIAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Chuey, A.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://masaba.github.io/" target="_blank" rel="noopener noreferrer">Asaba, M.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=1Wlj18oAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Bridgers, S.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://learninglab.yale.edu/meet-our-team" target="_blank" rel="noopener noreferrer">Carrillo, B.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://griffindietz.com/" target="_blank" rel="noopener noreferrer">Dietz, G.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://sll.stanford.edu/people.html" target="_blank" rel="noopener noreferrer">Garcia, T.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://jlnrd.github.io/" target="_blank" rel="noopener noreferrer">Leonard, J. A.</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Liu, S.</em>,
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://leadlab.sitehost.iu.edu/People/index.html" target="_blank" rel="noopener noreferrer">Merrick, M.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.com/citations?user=8S9IvwgAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Radwan, S.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="http://ecclabduke.com/graduate-students/2021/8/2/jessa-stegall" target="_blank" rel="noopener noreferrer">Stegall, J.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://nataliavelez.org/" target="_blank" rel="noopener noreferrer">Velez, N.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://bmwoo.github.io/" target="_blank" rel="noopener noreferrer">Woo, B.</a>,
                
              
            
          
        
          
          
          
          
            
              
            
          
          
          
            
              
                
                  Wu, Y.,
                
              
            
          
        
          
          
          
          
            
              
            
          
          
          
            
              
                
                  Zhou, X. J.,
                
              
            
          
        
          
          
          
          
            
              
            
          
          
          
            
              
                
                  Frank, M. C.,
                
              
            
          
        
          
          
          
          
            
              
            
          
          
          
            
              
                
                  and Gweon, H.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Front. Psychol.</em>
      
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    <a href="https://osf.io/mykph/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">materials</a>
  
    
      
      <a href="/assets/pdf/c_etal_2021_frontiers.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
      
      <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.734398/full#supplementary-material" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Supp</a>
      
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Online data collection methods are expanding the ease and access
              of developmental research for researchers and participants alike.
              While its popularity among developmental scientists has soared
              during the COVID-19 pandemic, its potential goes beyond just a
              means for safe, socially distanced data collection. In
              particular, advances in video conferencing software has enabled
              researchers to engage in face-to-face interactions with
              participants from nearly any location at any time. Due to the
              novelty of these methods, however, many researchers still remain
              uncertain about the differences in available approaches as well
              as the validity of online methods more broadly. In this article,
              we aim to address both issues with a focus on moderated
              (synchronous) data collected using video-conferencing software
              (e.g., Zoom). First, we review existing approaches for designing
              and executing moderated online studies with young children. We
              also present concrete examples of studies that implemented choice
              and verbal measures (Studies 1 and 2) and looking time (Studies 3
              and 4) across both in-person and online moderated data collection
              methods. Direct comparison of the two methods within each study
              as well as a meta-analysis of all studies suggest that the
              results from the two methods are comparable, providing empirical
              support for the validity of moderated online data collection.
              Finally, we discuss current limitations of online data collection
              and possible solutions, as well as its potential to increase the
              accessibility, diversity, and replicability of developmental
              science.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">working paper</abbr>
    
  
  </div>

  <div id="CTSL-pre" class="col-sm-8">
    
      <div class="title">iCatcher+: Robust and automatic gaze classification of infant
              webcam videos</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Cao, P.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tan, X.,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://kimberscott.github.io/" target="_blank" rel="noopener noreferrer">Scott, K. M.</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>Liu, S.</em>
              
            
          
        
      </div>

      <div class="periodical">
      
      
        Sep
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
    
      
      <a href="https://psyarxiv.com/s8c4m/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Studies of human infants provide a window into the origins of the
              mind, and collecting and annotating behavioral data from them
              remains slow and laborious. Although online platforms enable
              families to participate in studies via webcam, it remains time-
              and energy- consuming to manually annotate gaze directions on the
              collected videos. Existing gaze coding algorithms on videos
              either suffer from low video quality or still require
              considerable manual effort. In this project, we built on a
              promising system for automatic gaze annotation in human infants,
              iCatcher (Erel et al., 2020), and added two key additional
              features: a more robust infant face detector, and a gaze
              estimator that takes into account not only the features of the
              selected face, but where and how far it is from the screen. In
              our framework, iCatcher+, all possible faces in a video frame are
              first extracted by a face extractor, and then the infant face is
              selected by a infant selector; finally, the gaze direction is
              classified by a gaze estimator based on both the selected face
              and features of its bounding box. We evaluated iCatcher+ on a
              large-scale infant video dataset collected via webcam. The
              experimental results show improvements in gaze estimation
              accuracy, compared to the baseline framework. We see iCatcher+ as
              a key tool for enabling rapid large-scale studies of infant
              behavior.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@unpublished</span><span class="p">{</span><span class="nl">CTSL-pre</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{iCatcher+: Robust and automatic gaze classification of infant
                webcam videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cao, P. and Tan, X. and Scott, K. M. and Liu, S.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{eye-tracking; infancy; infant cognition; Lookit; online studies}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{working paper}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://psyarxiv.com/s8c4m/}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="nv">true</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>
</div>

    
    <hr>
    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%73%68%61%72%69%6C%69%75@%6D%69%74.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=ej0LI5YAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/shariliu" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>

<a href="https://twitter.com/liushari" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>











<a href="https://www.shariliu.com/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a>

      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2022 Shari  Liu.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: January 26, 2022.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
